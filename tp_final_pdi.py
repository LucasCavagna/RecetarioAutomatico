# -*- coding: utf-8 -*-
"""Tp final PDI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13jlCkcBSJpR63KvJ2MjVFAdtzaEH2ZBv

# **Trabajo Práctico de Porcesado de imagenes**

Participantes: Koatz, Camila; Cavagna, Lucas

## **Objetivo**

El objetivo principal de este trabajo práctico es aplicar los conceptos estudiados en la materia Procesado de Imágenes mediante el desarrollo de un proyecto práctico e interesante. En nuestro caso, proponemos crear un sistema que identifique piezas, estilo lego, a partir de imágenes de manera automática y, en función de la cantidad disponible que coloque el usuario, sugiera recetas predefinidas, por ejemplo un avión. De esta manera, combinamos técnicas de procesamiento de imágenes con un sistema de recomendación, aplicando los conocimientos adquiridos de forma práctica y útil; y obtenemos nuevos durante el trascurso del trabajo practico.

## Recetario automatizado

### Librerias

En esta seccion se encuntarn las librerias utilizadas a lo largo de la implementacion, junto con su funcion.
"""

import cv2                                      #Libreria de OpenCV para procesado de imagnes

import numpy as np                              #Libreria de manipulacion de arreglos numericos y funciones
                                                #matemáticas (computacion cientifica)

import matplotlib.pyplot as plt                 #Libreia para graficos y plot

import os                                       #Libreria para interactuar con el sistema operativo

from skimage.util import random_noise           #Libreria de donde sacamos la funcion para generer
                                                #diferentes tipos de ruido

from google.colab.patches import cv2_imshow     #Import especial de la libreria de OpenCV

from google.colab import files                  #Libreria para manejar archivos en google colab

from google.colab import drive                  #Libreria para interactuar con google drive

import shutil                                   #Libreria de operaciones de alto nivel sobre
                                                #archivos y colecciones de archivos.

import random                                   #Libreria para generar numeros aleatorios

import tensorflow as tf                         #Libreria de redes neuronales

from keras import layers,models                 #Libreria de simplificacion de tensorflow

from PIL import Image                           #Libreria para trabajar con imagenes

import io                                       #Libreria de manejo de imput y output

import ipywidgets as widgets                    #Libreria de widgets iterativos para los notebook de Jupyter

from IPython.display import display, clear_output

"""### Macros

En esta seccion se encuntarn las macros utilizadas a lo largo de la implementacion, junto con una descripcion.
"""

image_height = image_width = 720                                   #Alto de las imagen, Ancho de las imagen

categorias   = ["compuerta",
               "cuadrado",
               "cuadradoHueco",
               "parrilla",
               "puente",
               "rectangulo",
               "trianguloEquilatero",
               "ventana",
               "trianguloIsoceles"]                  #Nombres de las diferentes categorias

ruta_datos  = '/content/drive/MyDrive/output'        #Ruta de salida del data aumentation

"""### Configuracion de drive

En esta etapa del dessarrollo de nuestro recetario vamos a configurar todo lo necesario de los servicios de google
"""

drive.mount('/content/drive')

"""### Construcción - Data Aumentation


"""

#####Funciones de data aumentation#####

#Parametros para los ruidos

##Parametros ruido gusiano
limite_ruido_gau = 0.20
step_gau         = 0.10

##Parametros ruido sal y pimienta
limite_ruido_sp  = 0.10
step_sp          = 0.05

##Parametros ruido uniforme
limite_ruido_uni = 0.20
step_uni         = 0.10


def data_augmentation(image_path, output_dir):
    """
    Aplica data augmentation a una imagen o comunica si a ocurrido un error.

    Args:
        image_path: Ruta a la imagen de entrada.
        output_dir: Directorio de salida para las imágenes transformadas.
    """
    try:
        data_augmentation_process(image_path,output_dir)
    except Exception as e:
        print(e) # Print the error
        return None


def data_augmentation_process(image_path, output_dir):
    """
    Aplica data augmentation a una imagen.

    Args:
        image_path: Ruta a la imagen de entrada.
        output_dir: Directorio de salida para las imágenes transformadas.
    """

    #Verificaion de los argumentos

    ## 1. Verificar si la imagen existe y es un archivo:
    if not os.path.isfile(image_path):
        raise FileNotFoundError(f"ERROR-data_augmentation_process: La imagen no se encuentra en: {image_path}")

    ## 2. Verificar si el directorio de salida es válido:
    if not os.path.isdir(output_dir):
        raise NotADirectoryError(f"ERROR-data_augmentation_process: El directorio de salida no es válido: {output_dir}")

    ## 3. Intentar cargar la imagen con OpenCV:
    try:
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    except Exception as e:
        raise IOError(f"ERROR-data_augmentation_process: Error al cargar la imagen: {e}")

    # Si la imagen no se pudo cargar correctamente
    if image is None:
        raise ValueError("ERROR-data_augmentation_process: No se pudo leer la imagen. Puede estar dañada o en un formato no compatible.")

    # Redimensionar la imagen
    image = cv2.resize(image, (image_width,image_height), interpolation=cv2.INTER_AREA)

    # Diccionario para almacenar imágenes con sus etiquetas
    transformed_images = {"original": image}

    # Calculamos rotaciones de la imagen
    angles = [90, 180, 270]
    calcular_rotaciones(transformed_images,angles,image)

    #Espejo
    imagen_espejo_h = cv2.flip(image, 1)
    imagen_espejo_v = cv2.flip(image, 0)
    transformed_images[f"espejo_hor"] = imagen_espejo_h
    transformed_images[f"espejo_ver"] = imagen_espejo_v

    # Calculamos ruido a la imagen
    calcular_ruidos(transformed_images,image)

    # Guardar las imágenes con etiquetas como nombres de archivo
    guardado_de_imagenes_dic(transformed_images,output_dir)



def calcular_rotaciones(transformed_images,angles,image):
    """
    Calcula y agrega imágenes rotadas a un diccionario.

    Args:
        transformed_images: Diccionario para almacenar las imágenes transformadas.
        angles: Lista de ángulos de rotación en grados.
    """

    #Definimos el centro de una imagen
    center = (image.shape[1] / 2, image.shape[0] / 2)

    #Calculamos las rotaciones
    for angle in angles:

      rot_matrix = cv2.getRotationMatrix2D(center, angle, 1)
      rot_img = cv2.warpAffine(image, rot_matrix, (image.shape[1], image.shape[0]))
      transformed_images[f"rotacion_{angle}"] = rot_img



def calcular_ruidos(transformed_images,image):
    """
    Genera imágenes con tres diferentes ruidos.

    Args:
        transformed_images: Diccionario para almacenar las imágenes transformadas.
        image: Imagen original a la que se le aplicará el ruido.
    """

    #Ruido sal y pimienta
    producion_de_imagenes_con_ruido(transformed_images,image,limite_ruido_sp,step_sp,'s&p')

    #Ruido Gaussiano
    producion_de_imagenes_con_ruido(transformed_images,image,limite_ruido_gau,step_gau,'gaussian')

    #Ruido uniforme
    producion_de_imagenes_con_ruido(transformed_images,image,limite_ruido_uni,step_uni,'speckle')



def producion_de_imagenes_con_ruido(transformed_images,image,am,paso,type_n):
    """
    Genera imágenes con ruido y las agrega al diccionario transformed_images.

    Args:
        transformed_images: Diccionario para almacenar las imágenes transformadas.
        image: Imagen original a la que se le aplicará el ruido.
        am: Cantidad máxima de ruido a aplicar.
        paso: Incremento en la cantidad de ruido en cada paso.
        type_n: Tipo de ruido a aplicar ('s&p', 'gaussian', 'speckle').
    """

    #Verificaion de los argumentos

    ## 1. Validar 'am' (cantidad de ruido)
    if not isinstance(am, (int, float)) or am < 0:
        raise ValueError("ERROR-producion_de_imagenes_con_ruido: am debe ser un número no negativo.")

    ## 2. Validar 'paso' (incremento de ruido)
    if not isinstance(paso, (int, float)) or paso <= 0:
        raise ValueError("ERROR-producion_de_imagenes_con_ruido: paso debe ser un número positivo.")

    #Calculamos los pasos
    num_steps = int(am / paso)

    #Calculamos las imagenes con ruido
    for i in range(num_steps):

        amount = (i + 1) * paso

        if type_n == 's&p':
          noise_image = random_noise(image, mode=type_n, amount=amount)
        else:
          noise_image = random_noise(image, mode=type_n, var=amount)

        transformed_images[f"ruido_{type_n}_{int(amount * 100)}"] = (noise_image * 255).astype(np.uint8)


def guardado_de_imagenes_dic(transformed_images,output_dir):
    """
    Guarda las imágenes del diccionario en el directorio de salida.

    Args:
        transformed_images: Diccionario con las imágenes transformadas.
        output_dir: Directorio de salida para las imágenes transformadas.
    """
    for label, img in transformed_images.items():
      cv2.imwrite(os.path.join(output_dir, f"{label}.jpg"), img)

#####Funciones de carga y graficado de imagenes#####

def cargar_imagenes_directorio(directorio):
    """
    Carga imágenes de un directorio en un diccionario.

    Args:
        directorio: La ruta al directorio que contiene las imágenes.

    Returns:
        Un diccionario donde las claves son los nombres de las imágenes
        y los valores son las imágenes cargadas con OpenCV.
    """

    # Verificar si el directorio es válido
    if not os.path.isdir(directorio):
        raise NotADirectoryError(f"ERROR: El directorio no es válido: {directorio}")

    # Inicializa un diccionario vacío para almacenar las imágenes
    imagenes = {}

    # Recorrer los archivos en el directorio
    for filename in os.listdir(directorio):
        # Verificar si el archivo es una imagen
        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
            # Construir la ruta completa a la imagen
            ruta_imagen = os.path.join(directorio, filename)

            # Leer la imagen con OpenCV y convertirla a RGB
            imagen = cv2.imread(ruta_imagen)
            imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)

            # Agregar la imagen al diccionario
            imagenes[filename] = imagen

    return imagenes

def graficar_imagenes_dic(images, figsize=(15, 15), fontsize=12):
    """
    Grafica un diccionario de imágenes con nombres sin superposición (aproximado).

    Args:
        images (dict): Un diccionario donde las claves son los nombres de las imágenes
                       y los valores son las imágenes (numpy arrays).
        figsize (tuple, optional): Tamaño de la figura. Por defecto es (15, 15).
        fontsize (int, optional): Tamaño de la fuente de las etiquetas. Por defecto es 12.
    """
    #Verificaion de los argumentos

    ## 1. Verificar si el directorio es válido:
    if not isinstance(images, dict):
        raise ValueError("ERROR-graficar_imagenes_dic: El argumento 'images' debe ser un diccionario.")

    ## 2. Verificar si el directorio es válido:
    if not isinstance(figsize, tuple) or len(figsize) != 2:
        raise ValueError("ERROR-graficar_imagenes_dic: El argumento 'figsize' debe ser una tupla de dos elementos.")

    ## 3. Verificar si el directorio es válido:
    if not isinstance(fontsize, int) or fontsize <= 0:
        raise ValueError("ERROR-graficar_imagenes_dic: El argumento 'fontsize' debe ser un número entero positivo.")

    num_images = len(images)

    ## 4. Verificar si el directorio es válido:
    if num_images<=0:
        raise ValueError("ERROR-graficar_imagenes_dic: El directorio no tiene imagenes.")


    # Calcular el número de filas y columnas para la cuadrícula:
    num_cols = int(num_images**0.5)
    num_rows = (num_images + num_cols - 1) // num_cols

    # Crear la figura y los ejes:
    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize)
    axes = axes.flatten()  # Aplanar la matriz de ejes

    # Iterar sobre las imágenes y graficarlas:
    for i, (label, img) in enumerate(images.items()):
        ax = axes[i]
        ax.imshow(img)
        ax.axis('off')  # Ocultar los ejes de la imagen

        # Agregar la etiqueta de la imagen:
        ax.text(0.5, 0, label,  # Posición centrada en la parte superior
                ha='center', va='top', transform=ax.transAxes, fontsize=fontsize)

    # Ocultar los ejes sobrantes:
    for j in range(num_images, len(axes)):
        axes[j].axis('off')

    plt.tight_layout()  # Ajustar el espaciado entre las imágenes
    plt.show()  # Mostrar la gráfica

#####Ejmplificacion del data aumentation#####

directorio_de_muestra = '/content/drive/MyDrive/Muestra'
imagen_de_muestra     = '/content/drive/MyDrive/FtsSinObsmas/rectangulo/20241109_191806.jpg'

#Eliminamos el contenido de la carpeta de muestra
for filename in os.listdir(directorio_de_muestra):
    file_path = os.path.join(directorio_de_muestra, filename)
    try:
      if os.path.isfile(file_path) or os.path.islink(file_path):
        os.unlink(file_path)
      elif os.path.isdir(file_path):
        shutil.rmtree(file_path)
    except Exception as e:
      print('Failed to delete %s. Reason: %s' % (file_path, e))

# Recalcualmos la umentacion de la imagen de muestra
data_augmentation(imagen_de_muestra,directorio_de_muestra)

# Graficamos las imagnes resultantes de la aumentacion
imagenes_muestra=[]
try:

  imagenes_muestra=cargar_imagenes_directorio(directorio_de_muestra)

  graficar_imagenes_dic(imagenes_muestra)
except Exception as e:
  print(e)

#####Funciones para el procesado de todas las imagenes#####

def process_folder(input_dir, output_dir):
    """
    Toma todas las imágenes en un directorio de entrada y aplica data augmentation.

    Args:
        input_dir: Directorio de entrada que contiene las imágenes a procesar.
        output_dir: Directorio de salida donde se guardarán las imágenes aumentadas.
    """

    # Verificar si el directorio de salida existe, si no, lo crea
    os.makedirs(output_dir, exist_ok=True)

    # Recorrer cada archivo en el directorio de entrada
    for filename in os.listdir(input_dir):

        # Construir la ruta completa a la imagen
        image_path = os.path.join(input_dir, filename)

        # Verificar si el archivo es un archivo (no un directorio) y si tiene una extensión de imagen válida
        if os.path.isfile(image_path) and filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):
            # Obtener el nombre de la imagen sin la extensión
            image_name = os.path.splitext(filename)[0]

            # Construir la ruta al directorio de salida para esta imagen
            image_output_dir = os.path.join(output_dir, image_name)

            # Crear el directorio de salida para esta imagen si no existe
            os.makedirs(image_output_dir, exist_ok=True)

            # Llamar a la función data_augmentation para procesar la imagen
            data_augmentation(image_path, image_output_dir)


def data_aumentation_all(names):
  """
  Aplica data augmentation a todas las carpetas de categorias.

  Args:
      names: Una lista de nombres de carpetas que contienen imágenes para procesar.
  """
  count  = 1  # Inicializa un contador para mostrar el progreso
  length = len(names)  # Obtiene la cantidad total de carpetas a procesar

  # Itera sobre cada nombre de carpeta en la lista 'names'
  for name in names:
    # Imprime un mensaje de progreso en la consola
    print(f"Procesando carpeta {name}, {count} de {length}...")

    # Llama a la función 'process_folder' para procesar las imágenes en la carpeta actual
    # Especifica las rutas de entrada y salida para 'process_folder'
    process_folder(f'/content/drive/MyDrive/FtsSinObsmas/{name}', f'/content/drive/MyDrive/output/{name}')

    count += 1  # Incrementa el contador para la siguiente carpeta

#####Aplicamo las transfomaciones sobre todas las imagenes#####
data_aumentation_all(categorias)

"""### Construcción - Preparación del dataset y red neuronal

"""

datos       = []  # Lista de imagenes a utilizar como datos de testeo y entrenamiento

etiquetas   = []  # Lista de categorias a la que pertenececada una de las imagenes en "datos"


def cargar_data_set(datos, categorias, etiquetas, ruta_datos):
    """
    Carga imágenes y etiquetas de un directorio con subcarpetas y las agrega a las listas 'datos' y 'etiquetas'.
    También crea un diccionario 'ejemplos' con una imagen representativa de cada categoría.

    Args:
        datos: Una lista para almacenar las imágenes cargadas.
        categorias: Una lista de nombres de categorías.
        etiquetas: Una lista para almacenar las etiquetas correspondientes a las imágenes.
        ruta_datos: La ruta al directorio principal que contiene las subcarpetas de categorías.
    """

    ejemplos = {}  # Diccionario para almacenar una imagen de ejemplo por categoría

    # Recorrer las carpetas en el directorio principal
    for carpeta in os.listdir(ruta_datos):
        ruta_carpeta = os.path.join(ruta_datos, carpeta)  # Ruta completa a la carpeta

        # Verificar si la carpeta actual es un directorio
        if not os.path.isdir(ruta_carpeta):
            continue  # Saltar si no es un directorio

        # Recorrer las subcarpetas dentro de la carpeta actual
        for sub_carpeta in os.listdir(ruta_carpeta):
            ruta_sub_carpeta = os.path.join(ruta_carpeta, sub_carpeta)  # Ruta completa a la subcarpeta

            # Verificar si la subcarpeta actual es un directorio
            if not os.path.isdir(ruta_sub_carpeta):
                continue  # Saltar si no es un directorio

            # Recorrer los archivos dentro de la subcarpeta
            for archivo in os.listdir(ruta_sub_carpeta):
                ruta_img = os.path.join(ruta_sub_carpeta, archivo)  # Ruta completa a la imagen
                img = cv2.imread(ruta_img)  # Leer la imagen con OpenCV

                # Verificar si la imagen se pudo leer correctamente
                if img is None:
                    continue  # Saltar si no se pudo leer

                # Convertir la imagen de BGR (OpenCV) a RGB (matplotlib)
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                datos.append(img)  # Agregar la imagen a la lista 'datos'

                # Agregar la etiqueta correspondiente a la imagen
                if carpeta in categorias:
                    etiqueta = np.zeros(len(categorias))  # Crear un vector de etiquetas con ceros
                    etiqueta[categorias.index(carpeta)] = 1  # Poner 1 en la posición de la categoría
                    etiquetas.append(etiqueta)  # Agregar la etiqueta a la lista 'etiquetas'

        # Imprimir un mensaje indicando que se terminó de cargar la carpeta actual
        print(f"Cargando carpeta {carpeta}")

        # Agregar una imagen de ejemplo al diccionario 'ejemplos'
        ejemplos[carpeta] = datos[-1]  # Usar la última imagen cargada como ejemplo

    # Graficar las imágenes de ejemplo utilizando la función 'graficar_imagenes_dic'
    graficar_imagenes_dic(ejemplos)

# Llamada a la función
cargar_data_set(datos, categorias, etiquetas, ruta_datos)

# combinada es una lista de tuplas que une imagenes con su etiqueta
combinada = list(zip(datos, etiquetas))
# Se mezcla de manera random
random.shuffle(combinada)

# Desempaqueta estas tuplas y las separa en dos grupos y los vuelve a convertir en listas
datos, etiquetas = zip(*combinada)
datos = list(datos)
etiquetas = list(etiquetas)

# Variables
sizeLoteEntrenamiento=len(datos) * 80 // 100
start = 0
end = len(datos)

datos = np.array(datos)
etiquetas = np.array(etiquetas)

datos_entrenamiento = datos
etiquetas_entrenamiento = etiquetas

datos_entrenamiento_parts = np.array_split(datos_entrenamiento,10)
etiquetas_entrenamiento_parts = np.array_split(etiquetas_entrenamiento,10)

# Guardar cada parte en un archivo separado los distintos datasets de los entrenamientos
for i, parte in enumerate(datos_entrenamiento_parts):
  nombre_archivo = f'/content/drive/MyDrive/datasets/datos_entrenamiento_{i + 1}.npy'
  np.save(nombre_archivo, parte)
  print(f"Parte {i + 1} guardada en {nombre_archivo}")

# Guardar cada parte en un archivo separado las distintas etiquetas de los entrenamientos
for i, parte in enumerate(etiquetas_entrenamiento_parts):
  nombre_archivo = f'/content/drive/MyDrive/datasets/etiquetas_entrenamiento_{i + 1}.npy'
  np.save(nombre_archivo, parte)
  print(f"Parte {i + 1} guardada en {nombre_archivo}")

# Creación del modelo secuencial
model = tf.keras.Sequential()

# Capas de Convolución y Pooling:
# SeparableConv2D: Capa de convolución separable en profundidad.
# AveragePooling2D: Capa de pooling promedio para reducir la dimensionalidad.

model.add(layers.SeparableConv2D(64, (3, 3), activation='relu', input_shape=(image_height, image_width, 3)))
model.add(layers.AveragePooling2D((2, 2)))
model.add(layers.SeparableConv2D(32, (3, 3), activation='relu')) #add extra conv layer to reduce dimensionality
model.add(layers.AveragePooling2D((2, 2))) #add pooling to reduce dimensionality
model.add(layers.SeparableConv2D(16, (3, 3), activation='relu')) #add extra conv layer to reduce dimensionality
model.add(layers.AveragePooling2D((2, 2))) #add pooling to reduce dimensionality
model.add(layers.SeparableConv2D(8, (3, 3), activation='relu')) #add extra conv layer to reduce dimensionality
model.add(layers.AveragePooling2D((1, 1))) #add pooling to reduce dimensionality
model.add(layers.SeparableConv2D(8, (3, 3), activation='relu')) #add extra conv layer to reduce dimensionality
model.add(layers.AveragePooling2D((2, 2))) #add pooling to reduce dimensionality

# Aplana los datos para prepararlos para las capas densas.
model.add(layers.Flatten())

# Capa de salida con 9 neuronas y activación softmax, adecuada para clasificación multiclase.
model.add(layers.Dense(9, activation='softmax'))

model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer='adam', metrics=['accuracy']) # Change the loss function

def entrenar_modelo_eficiente(datassetsnum, ep):
    for i in range(datassetsnum):
        print(f"etapa numero {i}")

        # Cargar los datos de entrenamiento y sus etiquetas desde archivos .npy
        datos_entrenamiento = np.load(f'/content/drive/MyDrive/datasets/datos_entrenamiento_{i + 1}.npy')
        etiquetas_entrenamiento = np.load(f'/content/drive/MyDrive/datasets/etiquetas_entrenamiento_{i + 1}.npy')

        # Reducir el tamaño del lote para mejorar la eficiencia en caso de limitaciones de memoria
        batch_size = 1

        # Habilitar el crecimiento de memoria en TensorFlow para evitar el uso excesivo de memoria GPU
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            try:
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)
            except RuntimeError as e:
                print(e)

        # Convertir los datos de entrenamiento a float32 para mayor eficiencia en los cálculos
        datos_entrenamiento = datos_entrenamiento.astype(np.float32)

        # Entrenar el modelo con los datos cargados
        model.fit(datos_entrenamiento, etiquetas_entrenamiento, epochs=ep, batch_size=batch_size)

        # Guardar el modelo entrenado en la ruta especificada
        model.save('/content/drive/MyDrive/recetario.keras')

entrenar_modelo_eficiente(10, 4)

entrenar_modelo_eficiente(10, 4)

# 2. Cargar los pesos
new_model=tf.keras.models.load_model('/content/drive/MyDrive/recetario.keras')

# 3. Compilar el modelo (igual que antes)
new_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer='adam', metrics=['accuracy'])

# Test del nuevo modelo, extrae imagen del drive
# Modifica la imagen y predice con el modelo

test_image = cv2.imread("/content/drive/MyDrive/Copia de 20241109_191828.jpg")
test_image = cv2.resize(test_image, (image_width,image_height), interpolation=cv2.INTER_AREA)

test_image = test_image.reshape(1, image_height, image_width, 3)

predictions = new_model.predict(test_image)

index=predictions.argmax()

categoria    = categorias[index]
probabilidad = predictions[0,index]

print(f"La imagen pertenece a la categoria {categoria} con una probabilidad de {predictions}")

